> The reason we are (once again) having a fight about whether the producers of publicly available/published data should be authors on any work using said data is that we have a completely dysfunctional system for crediting the generation of useful data. {% cite eisenReasonWeAre2021 %}
>
> The same is true for people who generate useful reagents, resources and software. {% cite eisenSameTruePeople2021 %}
>
> And like everything, the real answer lies on how we assess candidates for jobs, grants, etc… So long as people treat authorship as the most/only valuable currency, this debate will fester. But it’s in our power to change it. - Michael Eisen, EIC eLife {% cite eisenEverythingRealAnswer2021 %}

The critical anchor for changes to the scientific infrastructural systems is the system of professional incentives that structure it. As long as the only thing that has professional value is authorship in journal papers, the system stays: Blog posts, analysis pathways, wikis, and forums are nice and all, but they don't count as *science.*

Imagining different systems of credit assignment is easy: just make a new DOI-like identifier for my datasets that I can put on my CV. Integrating systems of credit assignment into commonly-held beliefs about what is valuable is harder. One way to frame solutions to the credit assignment problem is as a collective action problem: everyone/funding agencies/hiring committees just need to *decide* that publishing data, reviewing, criticism et al. is valuable without any serious changes to broader scientific infrastructure. Another is to *displace* the system of credit assignment by aligning the interests of the broad array of researchers, technicians, and students that it directly impacts to build an alternative.

The sheer quantity of work that is currently uncredited in science is a structural advantage to any more expansive system of credit assignment. The strategic question is how to design a system that aligns the self-interest of everyone with uncredited work to build it. 

That's what I've tried to do here. Everything that exists in this system is attributable to one or many equal peers. Rather than attempting to be an abstract body of knowledge, clean and tidy, that conceals its social underpinnings, we embrace its messy and pluralistic personality. We have *not* been focused on some techno-utopian dream of automatically computing over a system of universally linked data, but on representing and negotiating over a globally discontinuous body of work and ideas linked to people and groups. We have *not* been imagining new platforms and services to suit a limited set of needs, but on a set of tools and frameworks to let people work together to cumulatively build what they need. 

Credit is woven throughout this system: the means of using someone else's work are tied to crediting it. While credit is currently meted out by proprietary journal aggregators like google scholar, citeseer, or web of science; downloading a dataset, using an analysis tool, and so on should be directly attributed to a digital identity that you control. 

The first-order effects for the usual suspects in need of credit are straightforward: counting the number of analyses and papers our datasets are cited in, seeing the type of experiments our software was used to perform. Control over the means of credit assignment also opens the possibility of surfacing the work that happens invisibly but is nonetheless essential for the normal operation of research. Why shouldn't the animal care technician receive credit for caring for the animals that were involved with a study, its results, and its impact on science more broadly?

Contextual technical knowledge is an example that warrants special consideration. Why would anyone spend the time to describe the fine technical details of how to use a type of motor, or which solenoids last the longest, or how to solder this particular type of circuit board? 

First (and hopefully familiarly), by making it practically useful for the researchers involved: say in this example we're using a lab wiki to coordinate work locally, using tools that can use the wiki information to automatically configure [solenoid](https://wiki.auto-pi-lot.com/index.php/Lee_LHDA0531115H) or [sensor](https://wiki.auto-pi-lot.com/index.php/TT_Electronics_OPB903L55) polarity, or the [dependencies for a sound card](https://wiki.auto-pi-lot.com/index.php/HiFiBerry_Amp2). 

Second, by making sure the researchers are credited for their work. A name prominently displayed on a wiki page and a permalink for a CV is ok, but clearly not enough. Foundational technical and documentation work like this is useful in itself, but its impact is mostly felt *downstream* in the work it enables. Beyond first-order credit, a linked credit assignment system lets us evaluate *higher-order* effects of work that *more closely resemble* the actual impact of the work. Say we find someone else's [3D Model](https://wiki.auto-pi-lot.com/index.php/3D_CAD), modify it for our use, and then use it to collect a dataset and publish a paper. Someone else sees it and links a colleague to it, and they too use it in their work. Over time someone else updates the design and puts it in some derivative component. Most of the linking is automatic, built into the interfaces of the relevant tools, and soon the network of links is dense and deep.

The incentives here are all aligned towards creating links and assigning credit: For us, instead of just getting professional credit for our paper, we also get credit for extending someone else's work, for documenting it, and for the potentially large number of nth-order derivative uses. Our credit extends multimodally, including papers that cite papers that use our tool, and the "amount" of credit can be contextualized because the type of link between them is explicit -- as opposed to the non-semantic links of citation. Our colleague that recommended our part gets credit as well, as they should since helpful communication is presumably something we want to reward. I *want* to use the extended graph of credit rather than just listing my paper because it's a lot more impressive! Since I want to be credited, I'm also invested in expanding the space of linked tools. Rather than the scarcity mindset of authorship, a link-based system can push us towards abundance: "good" work is work that engages with and extends a broad array of techniques, technologies, and expertise.

It's easy to imagine extended credit scenarios for a broad array of workers: since my work happens at `@institution`, and the `@institution:mice` are cared for by the members of the `@institution:animal_care` team, we can measure the impact of their work on the downstream work it supports. A grad student rotating in a lab might not get enough data to make a paper, but they might make some tangible improvement to lab infrastructure, which they can document and receive credit for. Open source software developers might get some credit from a code paper, but will be systematically undervalued from failure to cite it and undercounted in derivative packages. The many groups of workers whose work is formally excluded from scientific valuation are those with the most to gain by reimagining credit systems, and an infrastructural plan that actively involves them and elevates their work has a much broader base of labor, expertise, and potential for buy-in.

Some of my more communitarian colleagues might share my distaste for metricizing knowledge work --- but hiring committees and granting agencies are going to use *some* metric, the question is whether it's a good reflection of our work and who controls it. Our problems with the h-index (eg. {% cite teixeiradasilvaMultipleVersionsHindex2018 costasReflectionsCautionaryUse2018 %}) are problems with paper citations being a bad basis for evaluating scientific "value", and their primacy is in turn a consequence of the monopoly over scientific communication and organization by publishers and aggregators like Scopus and Google Scholar. Their successors, black box algorithmic tools like SciVal with valuation criteria that are bad for science (but good for administrators) like 'trendiness' are here whether we like it or not. A transparent graph of scientific credit at least gives the *possibility* for reimagining the more fundamental questions of scientific valuation: assigning credit for communication, maintenance, mentorship, and so on. So some misguided reductions of the complexity of scientific labor to a single number are inevitable, but at least we'll be able to *see what they're based on* and *propose alternatives.*

It's true that some of these extended metrics are already possible to compute. One could crawl package dependencies for code, or download the [100GB Crossref database](https://academictorrents.com/details/e4287cb7619999709f6e9db5c359dda17e93d515) {% cite crossrefJanuary2021Public2021 %} and manually crunch our statistics, but being *able* to compute some means of credit is very different than making it a *normal part* of doing and evaluating research. The multimodality of credit assignment that's possible with a linked data system is part of its power: our work *actually does* have impacts across modalities, and we should be able to represent that as part of our contribution to science. 

Reaching a critical mass of linked tools and peers is not altogether necessary for them to be useful, but critical mass may trigger a positive feedback loop for the development of the system itself. Even in isolation, a semantic wiki is a better means of assigning credit than a handful of google docs, experimental tools that automatically annotate data are better than a pile of `.csv` files, etc. Bridging two tools to share credit is better than one tool in isolation, and more people using them are better than fewer for any given user of the system. Lessons learned from STS, Computer-Supported Cooperative Work (CSCW), pirates, wikis, forums, et al. make it clear that *the labor of maintaining and building the system can't be invisible.* 

<div class="draft-text">Find citations and quote for ^^. Fortunately building a system for credit assignment should allow you to be credited! Conclude by talking about building more just system of valuing science, and that's one of the critical means by which any infrastructure might displace hegemonic systems! 
</div>

<div class="draft-text">
We want to be able to do stuff like "these 30 messages were me mentoring," without having any external access to the messages. This is a social question -- you can say you want to call the messages mentoring, ask the other person, and they can accept. It's an open question to me whether this is good, i don't personally like gamifying things, but this is a basic byproduct of people being able to negotiate over a system of meaning. At the point when it's possible for someone to say `@myname:mentorship` and then send `@menteename` a request to send an "affirm" message, then this is possible. 
</div>